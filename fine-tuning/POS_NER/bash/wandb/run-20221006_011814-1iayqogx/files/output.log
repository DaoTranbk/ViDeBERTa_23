
  0%|                                        | 0/1428 [00:00<?, ?it/s]/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|                                | 3/1428 [00:08<51:05,  2.15s/it]Traceback (most recent call last):
  File "../source/pos_vit5.py", line 729, in <module>
    main()
  File "../source/pos_vit5.py", line 648, in main
    train_result = trainer.train(resume_from_checkpoint=checkpoint)
  File "/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/transformers/trainer.py", line 1414, in train
    return inner_training_loop(
  File "/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/transformers/trainer.py", line 1656, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/transformers/trainer.py", line 2349, in training_step
    loss = self.compute_loss(model, inputs)
  File "/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/transformers/trainer.py", line 2381, in compute_loss
    outputs = model(**inputs)
  File "/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py", line 167, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py", line 177, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py", line 86, in parallel_apply
    output.reraise()
  File "/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/torch/_utils.py", line 429, in reraise
    raise self.exc_type(msg)
RuntimeError: Caught RuntimeError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py", line 61, in _worker
    output = module(*input, **kwargs)
  File "/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py", line 1637, in forward
    decoder_outputs = self.decoder(
  File "/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py", line 1033, in forward
    layer_outputs = layer_module(
  File "/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py", line 690, in forward
    cross_attention_outputs = self.layer[1](
  File "/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py", line 604, in forward
    attention_output = self.EncDecAttention(
  File "/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py", line 533, in forward
    attn_weights = nn.functional.dropout(
  File "/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/torch/nn/functional.py", line 1076, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
RuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 22.20 GiB total capacity; 19.37 GiB already allocated; 3.31 MiB free; 20.40 GiB reserved in total by PyTorch)