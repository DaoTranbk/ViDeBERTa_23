
  0%|                                                                                                                                                                                            | 0/5703 [00:00<?, ?it/s]/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '









































































































  9%|███████████████▌                                                                                                                                                                  | 500/5703 [03:47<38:02,  2.28it/s][INFO|trainer.py:2510] 2022-10-06 11:51:30,344 >> Saving model checkpoint to ../tmp/tst-summarization/checkpoint-500
[INFO|configuration_utils.py:451] 2022-10-06 11:51:30,345 >> Configuration saved in ../tmp/tst-summarization/checkpoint-500/config.json
{'loss': 0.3598, 'learning_rate': 4.5616342275995095e-05, 'epoch': 0.26}
[INFO|modeling_utils.py:1550] 2022-10-06 11:51:37,907 >> Model weights saved in ../tmp/tst-summarization/checkpoint-500/pytorch_model.bin
[INFO|tokenization_utils_base.py:2143] 2022-10-06 11:51:37,909 >> tokenizer config file saved in ../tmp/tst-summarization/checkpoint-500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2150] 2022-10-06 11:51:37,910 >> Special tokens file saved in ../tmp/tst-summarization/checkpoint-500/special_tokens_map.json
[INFO|tokenization_t5_fast.py:187] 2022-10-06 11:51:37,969 >> Copy vocab file to ../tmp/tst-summarization/checkpoint-500/spiece.model
/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '












































































































 18%|███████████████████████████████▏                                                                                                                                                  | 999/5703 [07:48<32:48,  2.39it/s]
 18%|███████████████████████████████                                                                                                                                                  | 1000/5703 [07:49<39:02,  2.01it/s][INFO|trainer.py:2510] 2022-10-06 11:55:31,719 >> Saving model checkpoint to ../tmp/tst-summarization/checkpoint-1000
[INFO|configuration_utils.py:451] 2022-10-06 11:55:31,721 >> Configuration saved in ../tmp/tst-summarization/checkpoint-1000/config.json
[INFO|modeling_utils.py:1550] 2022-10-06 11:55:38,336 >> Model weights saved in ../tmp/tst-summarization/checkpoint-1000/pytorch_model.bin
[INFO|tokenization_utils_base.py:2143] 2022-10-06 11:55:38,337 >> tokenizer config file saved in ../tmp/tst-summarization/checkpoint-1000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2150] 2022-10-06 11:55:38,340 >> Special tokens file saved in ../tmp/tst-summarization/checkpoint-1000/special_tokens_map.json
[INFO|tokenization_t5_fast.py:187] 2022-10-06 11:55:38,428 >> Copy vocab file to ../tmp/tst-summarization/checkpoint-1000/spiece.model
/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '









































































































 26%|██████████████████████████████████████████████▌                                                                                                                                  | 1500/5703 [11:42<34:14,  2.05it/s][INFO|trainer.py:2510] 2022-10-06 11:59:25,511 >> Saving model checkpoint to ../tmp/tst-summarization/checkpoint-1500
[INFO|configuration_utils.py:451] 2022-10-06 11:59:25,513 >> Configuration saved in ../tmp/tst-summarization/checkpoint-1500/config.json
{'loss': 0.0612, 'learning_rate': 3.6849026827985274e-05, 'epoch': 0.79}
[INFO|modeling_utils.py:1550] 2022-10-06 11:59:32,174 >> Model weights saved in ../tmp/tst-summarization/checkpoint-1500/pytorch_model.bin
[INFO|tokenization_utils_base.py:2143] 2022-10-06 11:59:32,176 >> tokenizer config file saved in ../tmp/tst-summarization/checkpoint-1500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2150] 2022-10-06 11:59:32,177 >> Special tokens file saved in ../tmp/tst-summarization/checkpoint-1500/special_tokens_map.json
[INFO|tokenization_t5_fast.py:187] 2022-10-06 11:59:32,225 >> Copy vocab file to ../tmp/tst-summarization/checkpoint-1500/spiece.model
/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '

































































































 35%|██████████████████████████████████████████████████████████████                                                                                                                   | 2000/5703 [15:20<27:15,  2.26it/s][INFO|trainer.py:2510] 2022-10-06 12:03:03,265 >> Saving model checkpoint to ../tmp/tst-summarization/checkpoint-2000
[INFO|configuration_utils.py:451] 2022-10-06 12:03:03,266 >> Configuration saved in ../tmp/tst-summarization/checkpoint-2000/config.json
{'loss': 0.051, 'learning_rate': 3.2465369103980366e-05, 'epoch': 1.05}
[INFO|modeling_utils.py:1550] 2022-10-06 12:03:10,692 >> Model weights saved in ../tmp/tst-summarization/checkpoint-2000/pytorch_model.bin
[INFO|tokenization_utils_base.py:2143] 2022-10-06 12:03:10,697 >> tokenizer config file saved in ../tmp/tst-summarization/checkpoint-2000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2150] 2022-10-06 12:03:10,699 >> Special tokens file saved in ../tmp/tst-summarization/checkpoint-2000/special_tokens_map.json
[INFO|tokenization_t5_fast.py:187] 2022-10-06 12:03:10,742 >> Copy vocab file to ../tmp/tst-summarization/checkpoint-2000/spiece.model
/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '


































































































 44%|█████████████████████████████████████████████████████████████████████████████▌                                                                                                   | 2499/5703 [19:01<19:51,  2.69it/s]
 44%|█████████████████████████████████████████████████████████████████████████████▌                                                                                                   | 2500/5703 [19:02<27:24,  1.95it/s][INFO|trainer.py:2510] 2022-10-06 12:06:45,064 >> Saving model checkpoint to ../tmp/tst-summarization/checkpoint-2500
[INFO|configuration_utils.py:451] 2022-10-06 12:06:45,065 >> Configuration saved in ../tmp/tst-summarization/checkpoint-2500/config.json
[INFO|modeling_utils.py:1550] 2022-10-06 12:06:52,462 >> Model weights saved in ../tmp/tst-summarization/checkpoint-2500/pytorch_model.bin
[INFO|tokenization_utils_base.py:2143] 2022-10-06 12:06:52,465 >> tokenizer config file saved in ../tmp/tst-summarization/checkpoint-2500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2150] 2022-10-06 12:06:52,465 >> Special tokens file saved in ../tmp/tst-summarization/checkpoint-2500/special_tokens_map.json
[INFO|tokenization_t5_fast.py:187] 2022-10-06 12:06:52,508 >> Copy vocab file to ../tmp/tst-summarization/checkpoint-2500/spiece.model
/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '


































































































 53%|█████████████████████████████████████████████████████████████████████████████████████████████                                                                                    | 2999/5703 [22:42<16:46,  2.69it/s]
 53%|█████████████████████████████████████████████████████████████████████████████████████████████                                                                                    | 3000/5703 [22:43<22:58,  1.96it/s][INFO|trainer.py:2510] 2022-10-06 12:10:25,705 >> Saving model checkpoint to ../tmp/tst-summarization/checkpoint-3000
[INFO|configuration_utils.py:451] 2022-10-06 12:10:25,706 >> Configuration saved in ../tmp/tst-summarization/checkpoint-3000/config.json
[INFO|modeling_utils.py:1550] 2022-10-06 12:10:27,592 >> Model weights saved in ../tmp/tst-summarization/checkpoint-3000/pytorch_model.bin
[INFO|tokenization_utils_base.py:2143] 2022-10-06 12:10:27,594 >> tokenizer config file saved in ../tmp/tst-summarization/checkpoint-3000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2150] 2022-10-06 12:10:27,595 >> Special tokens file saved in ../tmp/tst-summarization/checkpoint-3000/special_tokens_map.json
[INFO|tokenization_t5_fast.py:187] 2022-10-06 12:10:27,651 >> Copy vocab file to ../tmp/tst-summarization/checkpoint-3000/spiece.model
/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '

































































































 61%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                    | 3496/5703 [26:05<13:22,  2.75it/s]
 61%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                    | 3500/5703 [26:06<16:15,  2.26it/s][INFO|trainer.py:2510] 2022-10-06 12:13:49,582 >> Saving model checkpoint to ../tmp/tst-summarization/checkpoint-3500
[INFO|configuration_utils.py:451] 2022-10-06 12:13:49,584 >> Configuration saved in ../tmp/tst-summarization/checkpoint-3500/config.json
[INFO|modeling_utils.py:1550] 2022-10-06 12:13:51,512 >> Model weights saved in ../tmp/tst-summarization/checkpoint-3500/pytorch_model.bin
[INFO|tokenization_utils_base.py:2143] 2022-10-06 12:13:51,513 >> tokenizer config file saved in ../tmp/tst-summarization/checkpoint-3500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2150] 2022-10-06 12:13:51,514 >> Special tokens file saved in ../tmp/tst-summarization/checkpoint-3500/special_tokens_map.json
[INFO|tokenization_t5_fast.py:187] 2022-10-06 12:13:51,575 >> Copy vocab file to ../tmp/tst-summarization/checkpoint-3500/spiece.model
/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '

























































































































 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                     | 3998/5703 [30:15<16:18,  1.74it/s]
 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                    | 4000/5703 [30:17<19:37,  1.45it/s][INFO|trainer.py:2510] 2022-10-06 12:17:59,876 >> Saving model checkpoint to ../tmp/tst-summarization/checkpoint-4000
[INFO|configuration_utils.py:451] 2022-10-06 12:17:59,877 >> Configuration saved in ../tmp/tst-summarization/checkpoint-4000/config.json
[INFO|modeling_utils.py:1550] 2022-10-06 12:18:02,373 >> Model weights saved in ../tmp/tst-summarization/checkpoint-4000/pytorch_model.bin
[INFO|tokenization_utils_base.py:2143] 2022-10-06 12:18:02,375 >> tokenizer config file saved in ../tmp/tst-summarization/checkpoint-4000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2150] 2022-10-06 12:18:02,376 >> Special tokens file saved in ../tmp/tst-summarization/checkpoint-4000/special_tokens_map.json
[INFO|tokenization_t5_fast.py:187] 2022-10-06 12:18:02,458 >> Copy vocab file to ../tmp/tst-summarization/checkpoint-4000/spiece.model
/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '





































































































































 79%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                     | 4500/5703 [34:55<14:00,  1.43it/s][INFO|trainer.py:2510] 2022-10-06 12:22:37,757 >> Saving model checkpoint to ../tmp/tst-summarization/checkpoint-4500
[INFO|configuration_utils.py:451] 2022-10-06 12:22:37,758 >> Configuration saved in ../tmp/tst-summarization/checkpoint-4500/config.json
{'loss': 0.025, 'learning_rate': 1.0547080483955813e-05, 'epoch': 2.37}
[INFO|modeling_utils.py:1550] 2022-10-06 12:22:40,271 >> Model weights saved in ../tmp/tst-summarization/checkpoint-4500/pytorch_model.bin
[INFO|tokenization_utils_base.py:2143] 2022-10-06 12:22:40,272 >> tokenizer config file saved in ../tmp/tst-summarization/checkpoint-4500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2150] 2022-10-06 12:22:40,273 >> Special tokens file saved in ../tmp/tst-summarization/checkpoint-4500/special_tokens_map.json
[INFO|tokenization_t5_fast.py:187] 2022-10-06 12:22:40,307 >> Copy vocab file to ../tmp/tst-summarization/checkpoint-4500/spiece.model
/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '





































































































































 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                     | 5000/5703 [39:33<09:39,  1.21it/s][INFO|trainer.py:2510] 2022-10-06 12:27:16,417 >> Saving model checkpoint to ../tmp/tst-summarization/checkpoint-5000
[INFO|configuration_utils.py:451] 2022-10-06 12:27:16,418 >> Configuration saved in ../tmp/tst-summarization/checkpoint-5000/config.json
{'loss': 0.0253, 'learning_rate': 6.163422759950903e-06, 'epoch': 2.63}
[INFO|modeling_utils.py:1550] 2022-10-06 12:27:19,116 >> Model weights saved in ../tmp/tst-summarization/checkpoint-5000/pytorch_model.bin
[INFO|tokenization_utils_base.py:2143] 2022-10-06 12:27:19,117 >> tokenizer config file saved in ../tmp/tst-summarization/checkpoint-5000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2150] 2022-10-06 12:27:19,118 >> Special tokens file saved in ../tmp/tst-summarization/checkpoint-5000/special_tokens_map.json
[INFO|tokenization_t5_fast.py:187] 2022-10-06 12:27:19,164 >> Copy vocab file to ../tmp/tst-summarization/checkpoint-5000/spiece.model
/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '




































































































































 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋      | 5499/5703 [44:09<01:48,  1.87it/s]
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋      | 5500/5703 [44:11<02:45,  1.23it/s][INFO|trainer.py:2510] 2022-10-06 12:31:53,767 >> Saving model checkpoint to ../tmp/tst-summarization/checkpoint-5500
[INFO|configuration_utils.py:451] 2022-10-06 12:31:53,768 >> Configuration saved in ../tmp/tst-summarization/checkpoint-5500/config.json
[INFO|modeling_utils.py:1550] 2022-10-06 12:31:55,775 >> Model weights saved in ../tmp/tst-summarization/checkpoint-5500/pytorch_model.bin
[INFO|tokenization_utils_base.py:2143] 2022-10-06 12:31:55,777 >> tokenizer config file saved in ../tmp/tst-summarization/checkpoint-5500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2150] 2022-10-06 12:31:55,778 >> Special tokens file saved in ../tmp/tst-summarization/checkpoint-5500/special_tokens_map.json
[INFO|tokenization_t5_fast.py:187] 2022-10-06 12:31:55,846 >> Copy vocab file to ../tmp/tst-summarization/checkpoint-5500/spiece.model
/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
























































100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉| 5699/5703 [46:12<00:02,  1.84it/s]
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5703/5703 [46:14<00:00,  2.32it/s][INFO|trainer.py:1766] 2022-10-06 12:33:56,729 >>
Training completed. Do not forget to share your model on huggingface.co/models =)
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5703/5703 [46:14<00:00,  2.06it/s]
[INFO|trainer.py:2510] 2022-10-06 12:33:56,749 >> Saving model checkpoint to ../tmp/tst-summarization
[INFO|configuration_utils.py:451] 2022-10-06 12:33:56,755 >> Configuration saved in ../tmp/tst-summarization/config.json
***** train metrics *****
  epoch                    =        3.0
  train_loss               =     0.0681
  train_runtime            = 0:46:24.01
  train_samples            =      15201
  train_samples_per_second =      16.38
  train_steps_per_second   =      2.048
10/06/2022 12:34:03 - INFO - __main__ - *** Evaluate ***
[INFO|modeling_utils.py:1550] 2022-10-06 12:34:03,244 >> Model weights saved in ../tmp/tst-summarization/pytorch_model.bin
[INFO|tokenization_utils_base.py:2143] 2022-10-06 12:34:03,252 >> tokenizer config file saved in ../tmp/tst-summarization/tokenizer_config.json
[INFO|tokenization_utils_base.py:2150] 2022-10-06 12:34:03,254 >> Special tokens file saved in ../tmp/tst-summarization/special_tokens_map.json
[INFO|tokenization_t5_fast.py:187] 2022-10-06 12:34:03,356 >> Copy vocab file to ../tmp/tst-summarization/spiece.model
[INFO|trainer.py:2760] 2022-10-06 12:34:03,420 >> ***** Running Evaluation *****
[INFO|trainer.py:2762] 2022-10-06 12:34:03,421 >>   Num examples = 2045
[INFO|trainer.py:2765] 2022-10-06 12:34:03,421 >>   Batch size = 8































































































































































































































































100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [19:44<00:00,  3.92s/it]
***** eval metrics *****
  epoch                   =        3.0
  eval_gen_len            =   119.6577
  eval_loss               =     0.0396
  eval_rouge1             =    97.1229
  eval_rouge2             =    93.2353
  eval_rougeL             =    96.6357
  eval_rougeLsum          =     96.647
  eval_runtime            = 0:20:03.15
  eval_samples            =       2045
  eval_samples_per_second =        1.7
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [19:57<00:00,  4.68s/it]
[INFO|modelcard.py:460] 2022-10-06 12:54:07,661 >> Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Summarization', 'type': 'summarization'}, 'metrics': [{'name': 'Rouge1', 'type': 'rouge', 'value': 97.1229}]}