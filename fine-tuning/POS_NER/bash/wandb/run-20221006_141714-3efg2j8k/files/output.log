
  0%|                                                                                                                                                                                            | 0/2853 [00:00<?, ?it/s]/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '

















































































































































 18%|███████████████████████████████▏                                                                                                                                                  | 500/2853 [04:59<33:02,  1.19it/s][INFO|trainer.py:2510] 2022-10-06 14:22:18,816 >> Saving model checkpoint to ../tmp/tst-summarization/checkpoint-500
[INFO|configuration_utils.py:451] 2022-10-06 14:22:18,818 >> Configuration saved in ../tmp/tst-summarization/checkpoint-500/config.json
{'loss': 0.283, 'learning_rate': 4.12372940764108e-05, 'epoch': 0.53}
[INFO|modeling_utils.py:1550] 2022-10-06 14:22:25,953 >> Model weights saved in ../tmp/tst-summarization/checkpoint-500/pytorch_model.bin
[INFO|tokenization_utils_base.py:2143] 2022-10-06 14:22:25,957 >> tokenizer config file saved in ../tmp/tst-summarization/checkpoint-500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2150] 2022-10-06 14:22:25,960 >> Special tokens file saved in ../tmp/tst-summarization/checkpoint-500/special_tokens_map.json
[INFO|tokenization_t5_fast.py:187] 2022-10-06 14:22:26,008 >> Copy vocab file to ../tmp/tst-summarization/checkpoint-500/spiece.model
/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '



















































































































































 35%|██████████████████████████████████████████████████████████████                                                                                                                   | 1000/2853 [10:20<25:29,  1.21it/s][INFO|trainer.py:2510] 2022-10-06 14:27:39,098 >> Saving model checkpoint to ../tmp/tst-summarization/checkpoint-1000
[INFO|configuration_utils.py:451] 2022-10-06 14:27:39,099 >> Configuration saved in ../tmp/tst-summarization/checkpoint-1000/config.json
{'loss': 0.0595, 'learning_rate': 3.247458815282159e-05, 'epoch': 1.05}
[INFO|modeling_utils.py:1550] 2022-10-06 14:27:46,309 >> Model weights saved in ../tmp/tst-summarization/checkpoint-1000/pytorch_model.bin
[INFO|tokenization_utils_base.py:2143] 2022-10-06 14:27:46,310 >> tokenizer config file saved in ../tmp/tst-summarization/checkpoint-1000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2150] 2022-10-06 14:27:46,311 >> Special tokens file saved in ../tmp/tst-summarization/checkpoint-1000/special_tokens_map.json
[INFO|tokenization_t5_fast.py:187] 2022-10-06 14:27:46,357 >> Copy vocab file to ../tmp/tst-summarization/checkpoint-1000/spiece.model
/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
























































































































































 53%|█████████████████████████████████████████████████████████████████████████████████████████████                                                                                    | 1500/2853 [15:52<16:13,  1.39it/s][INFO|trainer.py:2510] 2022-10-06 14:33:10,920 >> Saving model checkpoint to ../tmp/tst-summarization/checkpoint-1500
[INFO|configuration_utils.py:451] 2022-10-06 14:33:10,921 >> Configuration saved in ../tmp/tst-summarization/checkpoint-1500/config.json
{'loss': 0.0421, 'learning_rate': 2.3711882229232387e-05, 'epoch': 1.58}
[INFO|modeling_utils.py:1550] 2022-10-06 14:33:18,314 >> Model weights saved in ../tmp/tst-summarization/checkpoint-1500/pytorch_model.bin
[INFO|tokenization_utils_base.py:2143] 2022-10-06 14:33:18,317 >> tokenizer config file saved in ../tmp/tst-summarization/checkpoint-1500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2150] 2022-10-06 14:33:18,317 >> Special tokens file saved in ../tmp/tst-summarization/checkpoint-1500/special_tokens_map.json
[INFO|tokenization_t5_fast.py:187] 2022-10-06 14:33:18,371 >> Copy vocab file to ../tmp/tst-summarization/checkpoint-1500/spiece.model
/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '





















































































































































 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                     | 2000/2853 [21:17<08:11,  1.74it/s][INFO|trainer.py:2510] 2022-10-06 14:38:35,929 >> Saving model checkpoint to ../tmp/tst-summarization/checkpoint-2000
[INFO|configuration_utils.py:451] 2022-10-06 14:38:35,930 >> Configuration saved in ../tmp/tst-summarization/checkpoint-2000/config.json
{'loss': 0.0364, 'learning_rate': 1.4949176305643184e-05, 'epoch': 2.1}
[INFO|modeling_utils.py:1550] 2022-10-06 14:38:43,315 >> Model weights saved in ../tmp/tst-summarization/checkpoint-2000/pytorch_model.bin
[INFO|tokenization_utils_base.py:2143] 2022-10-06 14:38:43,317 >> tokenizer config file saved in ../tmp/tst-summarization/checkpoint-2000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2150] 2022-10-06 14:38:43,317 >> Special tokens file saved in ../tmp/tst-summarization/checkpoint-2000/special_tokens_map.json
[INFO|tokenization_t5_fast.py:187] 2022-10-06 14:38:43,365 >> Copy vocab file to ../tmp/tst-summarization/checkpoint-2000/spiece.model
/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '






















































































































































 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                      | 2499/2853 [26:43<03:16,  1.80it/s]
 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                      | 2500/2853 [26:44<04:02,  1.46it/s][INFO|trainer.py:2510] 2022-10-06 14:44:03,579 >> Saving model checkpoint to ../tmp/tst-summarization/checkpoint-2500
[INFO|configuration_utils.py:451] 2022-10-06 14:44:03,580 >> Configuration saved in ../tmp/tst-summarization/checkpoint-2500/config.json
[INFO|modeling_utils.py:1550] 2022-10-06 14:44:10,007 >> Model weights saved in ../tmp/tst-summarization/checkpoint-2500/pytorch_model.bin
[INFO|tokenization_utils_base.py:2143] 2022-10-06 14:44:10,008 >> tokenizer config file saved in ../tmp/tst-summarization/checkpoint-2500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2150] 2022-10-06 14:44:10,009 >> Special tokens file saved in ../tmp/tst-summarization/checkpoint-2500/special_tokens_map.json
[INFO|tokenization_t5_fast.py:187] 2022-10-06 14:44:10,057 >> Copy vocab file to ../tmp/tst-summarization/checkpoint-2500/spiece.model
/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '

















































































































100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉| 2851/2853 [30:53<00:01,  1.50it/s]
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2853/2853 [30:54<00:00,  1.90it/s][INFO|trainer.py:1766] 2022-10-06 14:48:13,501 >>
Training completed. Do not forget to share your model on huggingface.co/models =)
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2853/2853 [30:54<00:00,  1.54it/s]
[INFO|trainer.py:2510] 2022-10-06 14:48:13,516 >> Saving model checkpoint to ../tmp/tst-summarization
[INFO|configuration_utils.py:451] 2022-10-06 14:48:13,517 >> Configuration saved in ../tmp/tst-summarization/config.json
***** train metrics *****
  epoch                    =        3.0
  train_loss               =     0.0825
  train_runtime            = 0:31:01.35
  train_samples            =      15201
  train_samples_per_second =       24.5
  train_steps_per_second   =      1.533
10/06/2022 14:48:19 - INFO - __main__ - *** Evaluate ***
[INFO|modeling_utils.py:1550] 2022-10-06 14:48:19,306 >> Model weights saved in ../tmp/tst-summarization/pytorch_model.bin
[INFO|tokenization_utils_base.py:2143] 2022-10-06 14:48:19,309 >> tokenizer config file saved in ../tmp/tst-summarization/tokenizer_config.json
[INFO|tokenization_utils_base.py:2150] 2022-10-06 14:48:19,316 >> Special tokens file saved in ../tmp/tst-summarization/special_tokens_map.json
[INFO|tokenization_t5_fast.py:187] 2022-10-06 14:48:19,371 >> Copy vocab file to ../tmp/tst-summarization/spiece.model
[INFO|trainer.py:2760] 2022-10-06 14:48:19,416 >> ***** Running Evaluation *****
[INFO|trainer.py:2762] 2022-10-06 14:48:19,416 >>   Num examples = 2045
[INFO|trainer.py:2765] 2022-10-06 14:48:19,416 >>   Batch size = 16































































































































100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [12:33<00:00,  5.10s/it]
***** eval metrics *****
  epoch                   =        3.0
  eval_gen_len            =   119.7516
  eval_loss               =      0.039
  eval_rouge1             =    97.1173
  eval_rouge2             =    93.2729
  eval_rougeL             =    96.6264
  eval_rougeLsum          =    96.6338
  eval_runtime            = 0:12:52.81
  eval_samples            =       2045
  eval_samples_per_second =      2.646
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [12:48<00:00,  6.00s/it]
[INFO|modelcard.py:460] 2022-10-06 15:01:13,272 >> Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Summarization', 'type': 'summarization'}, 'metrics': [{'name': 'Rouge1', 'type': 'rouge', 'value': 97.1173}]}