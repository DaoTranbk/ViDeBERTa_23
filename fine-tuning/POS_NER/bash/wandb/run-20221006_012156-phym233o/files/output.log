
  0%|                                                             | 0/2853 [00:00<?, ?it/s]/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '


















































































































































 18%|████████▉                                          | 500/2853 [04:59<28:27,  1.38it/s][INFO|trainer.py:2510] 2022-10-06 01:26:59,900 >> Saving model checkpoint to ../tmp/tst-summarization/checkpoint-500
[INFO|configuration_utils.py:451] 2022-10-06 01:26:59,901 >> Configuration saved in ../tmp/tst-summarization/checkpoint-500/config.json
{'loss': 0.2688, 'learning_rate': 4.12372940764108e-05, 'epoch': 0.53}
[INFO|modeling_utils.py:1550] 2022-10-06 01:27:01,524 >> Model weights saved in ../tmp/tst-summarization/checkpoint-500/pytorch_model.bin
[INFO|tokenization_utils_base.py:2143] 2022-10-06 01:27:01,525 >> tokenizer config file saved in ../tmp/tst-summarization/checkpoint-500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2150] 2022-10-06 01:27:01,526 >> Special tokens file saved in ../tmp/tst-summarization/checkpoint-500/special_tokens_map.json
[INFO|tokenization_t5_fast.py:187] 2022-10-06 01:27:01,575 >> Copy vocab file to ../tmp/tst-summarization/checkpoint-500/spiece.model
/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
















































































































































 35%|█████████████████▌                                | 1000/2853 [09:54<21:05,  1.46it/s][INFO|trainer.py:2510] 2022-10-06 01:31:55,404 >> Saving model checkpoint to ../tmp/tst-summarization/checkpoint-1000
[INFO|configuration_utils.py:451] 2022-10-06 01:31:55,405 >> Configuration saved in ../tmp/tst-summarization/checkpoint-1000/config.json
{'loss': 0.0598, 'learning_rate': 3.247458815282159e-05, 'epoch': 1.05}
[INFO|modeling_utils.py:1550] 2022-10-06 01:31:56,882 >> Model weights saved in ../tmp/tst-summarization/checkpoint-1000/pytorch_model.bin
[INFO|tokenization_utils_base.py:2143] 2022-10-06 01:31:56,883 >> tokenizer config file saved in ../tmp/tst-summarization/checkpoint-1000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2150] 2022-10-06 01:31:56,884 >> Special tokens file saved in ../tmp/tst-summarization/checkpoint-1000/special_tokens_map.json
[INFO|tokenization_t5_fast.py:187] 2022-10-06 01:31:56,927 >> Copy vocab file to ../tmp/tst-summarization/checkpoint-1000/spiece.model
/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
















































































































































 53%|██████████████████████████▎                       | 1500/2853 [14:51<16:29,  1.37it/s][INFO|trainer.py:2510] 2022-10-06 01:36:52,645 >> Saving model checkpoint to ../tmp/tst-summarization/checkpoint-1500
[INFO|configuration_utils.py:451] 2022-10-06 01:36:52,646 >> Configuration saved in ../tmp/tst-summarization/checkpoint-1500/config.json
{'loss': 0.0419, 'learning_rate': 2.3711882229232387e-05, 'epoch': 1.58}
[INFO|modeling_utils.py:1550] 2022-10-06 01:36:54,054 >> Model weights saved in ../tmp/tst-summarization/checkpoint-1500/pytorch_model.bin
[INFO|tokenization_utils_base.py:2143] 2022-10-06 01:36:54,055 >> tokenizer config file saved in ../tmp/tst-summarization/checkpoint-1500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2150] 2022-10-06 01:36:54,055 >> Special tokens file saved in ../tmp/tst-summarization/checkpoint-1500/special_tokens_map.json
[INFO|tokenization_t5_fast.py:187] 2022-10-06 01:36:54,097 >> Copy vocab file to ../tmp/tst-summarization/checkpoint-1500/spiece.model
/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
















































































































































 70%|███████████████████████████████████               | 1999/2853 [19:46<07:48,  1.82it/s]
 70%|███████████████████████████████████               | 2000/2853 [19:46<08:43,  1.63it/s][INFO|trainer.py:2510] 2022-10-06 01:41:47,587 >> Saving model checkpoint to ../tmp/tst-summarization/checkpoint-2000
[INFO|configuration_utils.py:451] 2022-10-06 01:41:47,589 >> Configuration saved in ../tmp/tst-summarization/checkpoint-2000/config.json
[INFO|modeling_utils.py:1550] 2022-10-06 01:41:49,018 >> Model weights saved in ../tmp/tst-summarization/checkpoint-2000/pytorch_model.bin
[INFO|tokenization_utils_base.py:2143] 2022-10-06 01:41:49,019 >> tokenizer config file saved in ../tmp/tst-summarization/checkpoint-2000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2150] 2022-10-06 01:41:49,019 >> Special tokens file saved in ../tmp/tst-summarization/checkpoint-2000/special_tokens_map.json
[INFO|tokenization_t5_fast.py:187] 2022-10-06 01:41:49,062 >> Copy vocab file to ../tmp/tst-summarization/checkpoint-2000/spiece.model
/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
















































































































































 88%|███████████████████████████████████████████▊      | 2500/2853 [24:42<03:51,  1.52it/s][INFO|trainer.py:2510] 2022-10-06 01:46:43,463 >> Saving model checkpoint to ../tmp/tst-summarization/checkpoint-2500
[INFO|configuration_utils.py:451] 2022-10-06 01:46:43,464 >> Configuration saved in ../tmp/tst-summarization/checkpoint-2500/config.json
{'loss': 0.0297, 'learning_rate': 6.186470382053978e-06, 'epoch': 2.63}
[INFO|modeling_utils.py:1550] 2022-10-06 01:46:44,925 >> Model weights saved in ../tmp/tst-summarization/checkpoint-2500/pytorch_model.bin
[INFO|tokenization_utils_base.py:2143] 2022-10-06 01:46:44,926 >> tokenizer config file saved in ../tmp/tst-summarization/checkpoint-2500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2150] 2022-10-06 01:46:44,927 >> Special tokens file saved in ../tmp/tst-summarization/checkpoint-2500/special_tokens_map.json
[INFO|tokenization_t5_fast.py:187] 2022-10-06 01:46:44,970 >> Copy vocab file to ../tmp/tst-summarization/checkpoint-2500/spiece.model
/media/data/huypn10/linear-transformer/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '





































































































100%|██████████████████████████████████████████████████| 2853/2853 [28:12<00:00,  2.35it/s][INFO|trainer.py:1766] 2022-10-06 01:50:13,118 >>
Training completed. Do not forget to share your model on huggingface.co/models =)
100%|██████████████████████████████████████████████████| 2853/2853 [28:12<00:00,  1.69it/s]
[INFO|trainer.py:2510] 2022-10-06 01:50:13,133 >> Saving model checkpoint to ../tmp/tst-summarization
[INFO|configuration_utils.py:451] 2022-10-06 01:50:13,134 >> Configuration saved in ../tmp/tst-summarization/config.json
{'train_runtime': 1698.602, 'train_samples_per_second': 26.847, 'train_steps_per_second': 1.68, 'train_loss': 0.07998942158909961, 'epoch': 3.0}
***** train metrics *****
  epoch                    =        3.0
  train_loss               =       0.08
  train_runtime            = 0:28:18.60
  train_samples            =      15201
  train_samples_per_second =     26.847
  train_steps_per_second   =       1.68
10/06/2022 01:50:14 - INFO - __main__ - *** Evaluate ***
[INFO|modeling_utils.py:1550] 2022-10-06 01:50:14,563 >> Model weights saved in ../tmp/tst-summarization/pytorch_model.bin
[INFO|tokenization_utils_base.py:2143] 2022-10-06 01:50:14,564 >> tokenizer config file saved in ../tmp/tst-summarization/tokenizer_config.json
[INFO|tokenization_utils_base.py:2150] 2022-10-06 01:50:14,564 >> Special tokens file saved in ../tmp/tst-summarization/special_tokens_map.json
[INFO|tokenization_t5_fast.py:187] 2022-10-06 01:50:14,607 >> Copy vocab file to ../tmp/tst-summarization/spiece.model
[INFO|trainer.py:2760] 2022-10-06 01:50:14,644 >> ***** Running Evaluation *****
[INFO|trainer.py:2762] 2022-10-06 01:50:14,644 >>   Num examples = 2045
[INFO|trainer.py:2765] 2022-10-06 01:50:14,644 >>   Batch size = 16
































































































































100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [09:16<00:00,  4.35s/it]
***** eval metrics *****
  epoch                   =        3.0
  eval_gen_len            =   119.6132
  eval_loss               =     0.0393
  eval_rouge1             =    97.1523
  eval_rouge2             =    93.2721
  eval_rougeL             =    96.6458
  eval_rougeLsum          =    96.6556
  eval_runtime            = 0:09:19.75
  eval_samples            =       2045
  eval_samples_per_second =      3.653
  eval_steps_per_second   =      0.229
[INFO|modelcard.py:460] 2022-10-06 01:59:35,460 >> Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Summarization', 'type': 'summarization'}, 'metrics': [{'name': 'Rouge1', 'type': 'rouge', 'value': 97.1523}]}